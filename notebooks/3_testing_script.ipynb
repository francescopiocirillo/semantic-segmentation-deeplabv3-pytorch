{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyO8w+1bVpBk0LBjX7SdQqVL"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yDP3FjS5P-T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1748591523214,
     "user_tz": -120,
     "elapsed": 2443,
     "user": {
      "displayName": "Diego GRAGNANIELLO",
      "userId": "02712514618197687193"
     }
    },
    "outputId": "6e50f71f-63cc-4f2f-e46b-e49fa91b1355"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/Didattica/ML/exam_2024-2025/project_work_segmentazione_off-road/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#IMPLEMENT HERE YOUR CODE"
   ],
   "metadata": {
    "id": "fcROIMDgI9Hn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##IMPLEMENT HERE THE FUNCTION TO LOAD YOUR MODEL\n",
    "For example, here we use a single convolutional layer."
   ],
   "metadata": {
    "id": "TTAQO9aPBJUZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn import Sequential, Conv2d\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation.deeplabv3 import ASPP\n",
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "class CustomDeepLabHead(nn.Sequential):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__(\n",
    "            ASPP(in_channels, [3, 7, 3]),  # ASPP con dilatazioni personalizzate\n",
    "            # üîÅ Primo layer convoluzionale: kernel 3x3\n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=2),  # mantiene dimensione\n",
    "            nn.ReLU(),\n",
    "            # üîÅ Secondo layer convoluzionale: kernel 5x5\n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=2),  # campo visivo pi√π ampio\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)      # output classi\n",
    "        )\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    weights = models.segmentation.DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "    model = models.segmentation.deeplabv3_resnet101(weights=weights)\n",
    "    \n",
    "    model.classifier = CustomDeepLabHead(2048, 9)\n",
    "    model.aux_classifier = None\n",
    "    \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.load_state_dict(torch.load(\"best_model_gruppo09_cirillo_fasolino.pth\", map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    return model"
   ],
   "metadata": {
    "id": "9_xVMtGJ6NgC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1748591530361,
     "user_tz": -120,
     "elapsed": 7149,
     "user": {
      "displayName": "Diego GRAGNANIELLO",
      "userId": "02712514618197687193"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-07-08T20:06:10.438258Z",
     "start_time": "2025-07-08T20:06:04.649328Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "##IMPLEMENT HERE YOUR PREDICT FUNCTION"
   ],
   "metadata": {
    "id": "-7BM4PXsBFjH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "def predict(model, X):\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    aug = A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # pre-processing\n",
    "        transformed = aug(image=X)\n",
    "\n",
    "        X = transformed['image']\n",
    "        X = X.unsqueeze(0)\n",
    "        X = X.to(DEVICE)\n",
    "        \n",
    "        # forward function\n",
    "        Y = model(X)[\"out\"]\n",
    "        \n",
    "        # post-processing\n",
    "        Y = F.interpolate(Y, size=(544, 1024), mode='bilinear', align_corners=False)\n",
    "        Y = torch.argmax(Y, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "    return Y"
   ],
   "metadata": {
    "id": "TtKO0n6r8JAz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1748591530404,
     "user_tz": -120,
     "elapsed": 40,
     "user": {
      "displayName": "Diego GRAGNANIELLO",
      "userId": "02712514618197687193"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-07-08T20:06:15.283691Z",
     "start_time": "2025-07-08T20:06:11.727265Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "#DO NOT MODIFY THE CODE BELOW!\n",
    "\n",
    "This is exactly the code we run for the final test.\n",
    "\n",
    "After implementing the previous functions, run this code to verify that it works"
   ],
   "metadata": {
    "id": "Jdz_Q0lKApMW"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T20:06:44.928514Z",
     "start_time": "2025-07-08T20:06:18.801342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Metrics\n",
    "def compute_iou(mask1, mask2, label):\n",
    "  intersection = np.sum((mask1 == label) & (mask2 == label))\n",
    "  union = np.sum((mask1 == label) | (mask2 == label))\n",
    "  if union == 0:\n",
    "    return np.nan\n",
    "  return intersection / union\n",
    "def compute_all_iou(mask1, mask2, num_labels=8):\n",
    "  iou_scores = np.zeros((num_labels))\n",
    "  for label in range(num_labels):\n",
    "    iou = compute_iou(mask1, mask2, label+1) # we skip the background label\n",
    "    iou_scores[label] = iou\n",
    "  return iou_scores\n",
    "\n",
    "\n",
    "# Run YOUR LOAD_MODEL FUNCTION\n",
    "model = load_model()\n",
    "\n",
    "# Main loop\n",
    "test_dir = \"./train\"  # we will change this path with that of the private test set directory\n",
    "samples = os.listdir(test_dir)\n",
    "IOUs = np.zeros((len(samples), 8))\n",
    "verbose = False\n",
    "\n",
    "for i, subdir in tqdm(enumerate(samples), desc=\"Processing samples\"):\n",
    "    subdir_path = os.path.join(test_dir, subdir)\n",
    "\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Get the data paths\n",
    "        rgb_path = os.path.join(subdir_path, 'rgb.jpg')\n",
    "        labels_path = os.path.join(subdir_path, 'labels.png')\n",
    "\n",
    "        if os.path.exists(rgb_path) and os.path.exists(labels_path):\n",
    "            if verbose:\n",
    "                print(f\"Processing subdirectory: {subdir}\")\n",
    "\n",
    "            try:  # ATTENTION: any error occurring in this try-catch means that the corresponding IOUs are evaluated as ZERO\n",
    "\n",
    "                # Open images\n",
    "                rgb_image = Image.open(rgb_path)\n",
    "                rgb_array = np.asarray(rgb_image).copy()\n",
    "                labels_image = Image.open(labels_path).copy()\n",
    "                labels_array = np.asarray(labels_image)\n",
    "                if verbose:\n",
    "                    print(f\"  Loaded {rgb_path} and {labels_path}\")\n",
    "\n",
    "                # Run YOUR PREDICT FUNCTION\n",
    "                predicted_labels_array = predict(model, rgb_array)\n",
    "\n",
    "                # Evaluate the IOU metric\n",
    "                IOUs[i,:] = compute_all_iou(labels_array, predicted_labels_array)\n",
    "\n",
    "                if verbose:\n",
    "                    labels_vals = np.unique(np.asarray(labels_image))\n",
    "                    print(f\"  Unique labels values: {labels_vals}\")\n",
    "                    predicted_labels_vals = np.unique(np.asarray(predicted_labels_array))\n",
    "                    print(f\"  Unique predicted labels values: {predicted_labels_vals}\")\n",
    "\n",
    "                    plt.subplot(1, 3, 1)\n",
    "                    plt.imshow(rgb_image)\n",
    "                    plt.subplot(1, 3, 2)\n",
    "                    plt.imshow(labels_image)\n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    plt.imshow(predicted_labels_array)\n",
    "                    plt.show()\n",
    "\n",
    "                rgb_image.close()\n",
    "                labels_image.close()\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"  Error: Could not find image files in {subdir_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing images in {subdir_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"  Skipping subdirectory {subdir}: rgb.jpg or labels.png not found.\")\n",
    "\n",
    "score = np.nanmean(IOUs)\n",
    "print(f\"\\nFinal competition score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\.conda\\envs\\machine-learning\\Lib\\site-packages\\torch\\cuda\\memory.py:391: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Processing samples: 177it [00:22,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final competition score: 0.5512581817945086\n",
      "üîù Max GPU RAM usata quest'epoca: 0.52 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "More information useful for"
   ],
   "metadata": {
    "id": "BGahGEPvLcX7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(f\"All IOUs:\\n{IOUs}\")\n",
    "print(\"Average IOUs for each:\")\n",
    "print(f\"- class: {np.nanmean(IOUs, 0)}\")\n",
    "print(f\"- image: {np.nanmean(IOUs, 1)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZS1At0nkINS3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1748591534981,
     "user_tz": -120,
     "elapsed": 30,
     "user": {
      "displayName": "Diego GRAGNANIELLO",
      "userId": "02712514618197687193"
     }
    },
    "outputId": "3239702c-fdf4-4649-bda4-a32d4acb73f8",
    "ExecuteTime": {
     "end_time": "2025-07-08T20:06:45.169365Z",
     "start_time": "2025-07-08T20:06:45.159011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All IOUs:\n",
      "[[0.829 0.683   nan ...   nan 0.962 0.683]\n",
      " [0.942 0.      nan ...   nan 0.934 0.964]\n",
      " [0.985   nan   nan ...   nan 0.966 0.946]\n",
      " ...\n",
      " [0.762 0.754 0.    ...   nan 0.959 0.742]\n",
      " [0.779 0.766   nan ...   nan 0.941 0.614]\n",
      " [0.818 0.779   nan ...   nan 0.949 0.676]]\n",
      "Average IOUs for each:\n",
      "- class: [0.539 0.461 0.418 0.421 0.124 0.167 0.818 0.84 ]\n",
      "- image: [0.789 0.71  0.966 0.68  0.521 0.5   0.296 0.56  0.429 0.347 0.624 0.429\n",
      " 0.648 0.336 0.393 0.432 0.819 0.491 0.358 0.672 0.7   0.453 0.456 0.575\n",
      " 0.611 0.79  0.545 0.445 0.651 0.464 0.875 0.387 0.471 0.822 0.403 0.422\n",
      " 0.587 0.452 0.358 0.528 0.526 0.334 0.362 0.453 0.666 0.424 0.635 0.393\n",
      " 0.638 0.712 0.416 0.953 0.669 0.873 0.535 0.919 0.747 0.343 0.601 0.366\n",
      " 0.755 0.33  0.52  0.412 0.543 0.417 0.554 0.27  0.427 0.426 0.465 0.249\n",
      " 0.428 0.364 0.301 0.888 0.467 0.611 0.71  0.497 0.458 0.703 0.467 0.546\n",
      " 0.517 0.874 0.426 0.284 0.422 0.932 0.956 0.362 0.401 0.264 0.485 0.415\n",
      " 0.67  0.551 0.445 0.483 0.63  0.87  0.942 0.345 0.453 0.119 0.394 0.303\n",
      " 0.718 0.426 0.882 0.653 0.566 0.399 0.674 0.654 0.706 0.314 0.479 0.544\n",
      " 0.531 0.653 0.925 0.941 0.731 0.621 0.595 0.655 0.646 0.796 0.545 0.495\n",
      " 0.519 0.744 0.364 0.597 0.561 0.656 0.416 0.533 0.502 0.517 0.594 0.487\n",
      " 0.414 0.593 0.552 0.413 0.401 0.394 0.445 0.512 0.374 0.872 0.74  0.517\n",
      " 0.859 0.853 0.73  0.833 0.868 0.541 0.601 0.656 0.887 0.875 0.827 0.862\n",
      " 0.863 0.867 0.81  0.814 0.826 0.669 0.643 0.775 0.805]\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ]
}
